<h1 align="center">
  Literary-Alpaca2
</h1>

<p align="center">
  <font face="é»‘ä½“" color=orange size="6"> ä»è¯è¡¨åˆ°å¾®è°ƒè¿™å°±æ˜¯ä½ éœ€è¦çš„ä¸€åˆ‡ </font>
</p>

</br></br>


## ğŸ—‚ï¸ ä½¿ç”¨æŒ‡å—
- [ğŸ”¥ é¡¹ç›®ä»‹ç»](#-ç¤¾åŒºä»‹ç»llamaä¸­æ–‡ç¤¾åŒº)
- [ğŸ“ ä¸­æ–‡æ•°æ®](#-ä¸­æ–‡æ•°æ®)
- [â¬ æ¨¡å‹éƒ¨ç½²](#-æ¨¡å‹éƒ¨ç½²)
  - [æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)
    - [Metaå®˜æ–¹Llama2æ¨¡å‹](#metaå®˜æ–¹llama2æ¨¡å‹)
    - [åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#åŸºäºllama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹)
    - [åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom](#åŸºäºllama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹atom)
  - [æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹](#æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹)
  - [Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°](#gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°)
- [ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ](#-æ¨¡å‹é¢„è®­ç»ƒ)
- [ğŸ’¡ æ¨¡å‹å¾®è°ƒ](#-æ¨¡å‹å¾®è°ƒ)
  - [Step1: ç¯å¢ƒå‡†å¤‡](#step1-ç¯å¢ƒå‡†å¤‡)
  - [Step2: æ•°æ®å‡†å¤‡](#step2-æ•°æ®å‡†å¤‡)
  - [Step3: å¾®è°ƒè„šæœ¬](#step3-å¾®è°ƒè„šæœ¬)
    - [LoRAå¾®è°ƒ](#loraå¾®è°ƒ)
    - [å…¨é‡å‚æ•°å¾®è°ƒ](#å…¨é‡å‚æ•°å¾®è°ƒ)
  - [Step4: åŠ è½½å¾®è°ƒæ¨¡å‹](#step4-åŠ è½½å¾®è°ƒæ¨¡å‹)
    - [LoRAå¾®è°ƒ](#loraå¾®è°ƒ-1)
    - [å…¨é‡å‚æ•°å¾®è°ƒ](#å…¨é‡å‚æ•°å¾®è°ƒ-1)
- [ğŸ„ æ¨¡å‹é‡åŒ–](#-æ¨¡å‹é‡åŒ–)
- [ğŸ¥‡ æ¨¡å‹è¯„æµ‹](#-æ¨¡å‹è¯„æµ‹)
  - [LangChain](#langchain)
  - [Llamaç›¸å…³è®ºæ–‡](#llamaç›¸å…³è®ºæ–‡)
  - [Llama2çš„è¯„æµ‹ç»“æœ](#llama2çš„è¯„æµ‹ç»“æœ)



## ğŸ”¥ é¡¹ç›®ä»‹ç»

æ¬¢è¿æ¥åˆ°Llamaä¸­æ–‡ç¤¾åŒºï¼æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlamaæ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚
**\*åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§\***ã€‚
æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚

æœ¬ä»“åº“ä¸­çš„ä»£ç ç¤ºä¾‹ä¸»è¦æ˜¯åŸºäºHugging Faceç‰ˆæœ¬å‚æ•°è¿›è¡Œè°ƒç”¨ã€‚






## ğŸ“ ä¸­æ–‡æ•°æ®

æˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ•°æ®æ¥ä¼˜åŒ–Llama2çš„ä¸­æ–‡èƒ½åŠ›:

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| ç½‘ç»œæ•°æ®                                                   | äº’è”ç½‘ä¸Šå…¬å¼€çš„ç½‘ç»œæ•°æ®ï¼ŒæŒ‘é€‰å‡ºå»é‡åçš„é«˜è´¨é‡ä¸­æ–‡æ•°æ®ï¼Œæ¶‰åŠåˆ°ç™¾ç§‘ã€ä¹¦ç±ã€åšå®¢ã€æ–°é—»ã€å…¬å‘Šã€å°è¯´ç­‰é«˜è´¨é‡é•¿æ–‡æœ¬æ•°æ®ã€‚ |
| [Wikipedia](https://github.com/goldsmith/Wikipedia)        | ä¸­æ–‡Wikipediaçš„æ•°æ®                                          |
| [æ‚Ÿé“](https://github.com/BAAI-WuDao/Model)                | ä¸­æ–‡æ‚Ÿé“å¼€æºçš„200Gæ•°æ®                                       |
| [Clue](https://github.com/CLUEbenchmark/CLUEDatasetSearch) | Clueå¼€æ”¾çš„ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®ï¼Œè¿›è¡Œæ¸…æ´—åçš„é«˜è´¨é‡ä¸­æ–‡é•¿æ–‡æœ¬æ•°æ®   |
| ç«èµ›æ•°æ®é›†                                                 | è¿‘å¹´æ¥ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡ç«èµ›æ•°æ®é›†ï¼Œçº¦150ä¸ª              |
| [MNBVC](https://github.com/esbatmop/MNBVC)                 | MNBVC ä¸­æ¸…æ´—å‡ºæ¥çš„éƒ¨åˆ†æ•°æ®é›†                                 |

**å¸Œæœ›å¤§å®¶å¦‚æœæœ‰è¾ƒé«˜è´¨é‡çš„æ•°æ®é›†èƒ½å¤Ÿæä¾›ç»™æˆ‘ä»¬ï¼Œä¸èƒœæ„Ÿæ¿€!ğŸ’•ğŸ’•**



## â¬ æ¨¡å‹éƒ¨ç½²

Metaåœ¨ğŸ¤—Hugging Faceä¸Šæä¾›äº†æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼šhttps://huggingface.co/meta-llama

æœ¬é¡¹ç›®æ¨¡å‹ä¸‹è½½é“¾æ¥ï¼šhttps://huggingface.co/taotie1

### æ¨¡å‹ä¸‹è½½


#### åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹

æˆ‘ä»¬åŸºäºä¸­æ–‡æŒ‡ä»¤æ•°æ®é›†å¯¹Llama2-Chatæ¨¡å‹è¿›è¡Œäº†å¾®è°ƒï¼Œä½¿å¾—Llama2æ¨¡å‹æœ‰ç€æ›´å¼ºçš„ä¸­æ–‡å¯¹è¯èƒ½åŠ›ã€‚LoRAå‚æ•°ä»¥åŠä¸åŸºç¡€æ¨¡å‹åˆå¹¶çš„å‚æ•°å‡å·²ä¸Šä¼ è‡³[Hugging Face](https://huggingface.co/FlagAlpha)ï¼Œç›®å‰åŒ…å«7Bå’Œ13Bçš„æ¨¡å‹ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | åŸºç¡€æ¨¡å‹ç‰ˆæœ¬ |    ä¸‹è½½åœ°å€                                                     |
|  ----------  | ---------- | ------------- |  ----------------- | ------------------- |
|  åˆå¹¶å‚æ•° | Llama2-Chinese-13b-Chat | FlagAlpha/Llama2-Chinese-13b-Chat|     meta-llama/Llama-2-13b-chat-hf     |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat) |
|  LoRAå‚æ•° | Llama2-Chinese-13b-Chat-LoRA | FlagAlpha/Llama2-Chinese-13b-Chat-LoRA |     meta-llama/Llama-2-13b-chat-hf     |[æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-LoRA) |


#### åŸºäºLlama2çš„ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹Atom

ç¤¾åŒºæä¾›é¢„è®­ç»ƒç‰ˆæœ¬Atom-7Bå’ŒåŸºäºAtom-7Bè¿›è¡Œå¯¹è¯å¾®è°ƒçš„æ¨¡å‹å‚æ•°ä¾›å¼€æ”¾ä¸‹è½½ï¼Œæ¨¡å‹å‚æ•°ä¼šæŒç»­ä¸æ–­æ›´æ–°ï¼Œå…³äºæ¨¡å‹çš„è¿›å±•è¯¦è§ç¤¾åŒºå®˜ç½‘[llama.family](https://llama.family)ã€‚

|  ç±»åˆ«  | æ¨¡å‹åç§°        | ğŸ¤—æ¨¡å‹åŠ è½½åç§°                  | ä¸‹è½½åœ°å€                                                     |
| --------------- | --------------- | ------------------------------ | ------------------------------------------------------------ |
|  é¢„è®­ç»ƒ  | Atom-7B  | FlagAlpha/Atom-7B  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Atom-7B) |
|  Chat  | Atom-7B-Chat  | FlagAlpha/Atom-7B-Chat  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/FlagAlpha/Atom-7B-Chat) |


### æ¨¡å‹è°ƒç”¨ä»£ç ç¤ºä¾‹

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained('FlagAlpha/Atom-7B',device_map='auto',torch_dtype=torch.float16,load_in_8bit=True)
model =model.eval()
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Atom-7B',use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹ä¸­å›½\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```

### Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°

åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°äº†æµå¼çš„è¾“å‡ºï¼Œå°†ä¸‹é¢ä»£ç å¤åˆ¶åˆ°æ§åˆ¶å°è¿è¡Œï¼Œä»¥ä¸‹ä»£ç ä»¥Atom-7Bæ¨¡å‹ä¸ºä¾‹ï¼Œ<font color="#006600">ä¸åŒæ¨¡å‹åªéœ€ä¿®æ”¹ä¸€ä¸‹ä»£ç é‡Œçš„æ¨¡å‹åç§°å°±å¥½äº†ğŸ˜Š</font><br/>
```
python examples/chat_gradio.py --model_name_or_path FlagAlpha/Atom-7B
```

## ğŸ¤– æ¨¡å‹é¢„è®­ç»ƒ
è™½ç„¶Llama2çš„é¢„è®­ç»ƒæ•°æ®ç›¸å¯¹äºç¬¬ä¸€ä»£LLaMAæ‰©å¤§äº†ä¸€å€ï¼Œä½†æ˜¯ä¸­æ–‡é¢„è®­ç»ƒæ•°æ®çš„æ¯”ä¾‹ä¾ç„¶éå¸¸å°‘ï¼Œä»…å 0.13%ï¼Œè¿™ä¹Ÿå¯¼è‡´äº†åŸå§‹Llama2çš„ä¸­æ–‡èƒ½åŠ›è¾ƒå¼±ã€‚ä¸ºäº†èƒ½å¤Ÿæå‡æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ï¼Œå¯ä»¥é‡‡ç”¨å¾®è°ƒå’Œé¢„è®­ç»ƒä¸¤ç§è·¯å¾„ï¼Œå…¶ä¸­ï¼š
- å¾®è°ƒéœ€è¦çš„ç®—åŠ›èµ„æºå°‘ï¼Œèƒ½å¤Ÿå¿«é€Ÿå®ç°ä¸€ä¸ªä¸­æ–‡Llamaçš„é›å½¢ã€‚ä½†ç¼ºç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œåªèƒ½æ¿€å‘åŸºåº§æ¨¡å‹å·²æœ‰çš„ä¸­æ–‡èƒ½åŠ›ï¼Œç”±äºLlama2çš„ä¸­æ–‡è®­ç»ƒæ•°æ®æœ¬èº«è¾ƒå°‘ï¼Œæ‰€ä»¥èƒ½å¤Ÿæ¿€å‘çš„èƒ½åŠ›ä¹Ÿæœ‰é™ï¼Œæ²»æ ‡ä¸æ²»æœ¬ã€‚

- åŸºäºå¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒï¼Œæˆæœ¬é«˜ï¼Œä¸ä»…éœ€è¦å¤§è§„æ¨¡é«˜è´¨é‡çš„ä¸­æ–‡æ•°æ®ï¼Œä¹Ÿéœ€è¦å¤§è§„æ¨¡çš„ç®—åŠ›èµ„æºã€‚ä½†æ˜¯ä¼˜ç‚¹ä¹Ÿæ˜¾è€Œæ˜“è§ï¼Œå°±æ˜¯èƒ½ä»æ¨¡å‹åº•å±‚ä¼˜åŒ–ä¸­æ–‡èƒ½åŠ›ï¼ŒçœŸæ­£è¾¾åˆ°æ²»æœ¬çš„æ•ˆæœï¼Œä»å†…æ ¸ä¸ºå¤§æ¨¡å‹æ³¨å…¥å¼ºå¤§çš„ä¸­æ–‡èƒ½åŠ›ã€‚

æˆ‘ä»¬ä¸ºç¤¾åŒºæä¾›äº†Llamaæ¨¡å‹çš„é¢„è®­ç»ƒä»£ç ï¼Œä»¥åŠ[ä¸­æ–‡æµ‹è¯•è¯­æ–™](https://github.com/FlagAlpha/Llama2-Chinese/tree/main/data)ï¼Œæ›´å¤šæ•°æ®å¯ä»¥å‚è€ƒ[ä¸­æ–‡è¯­æ–™](#-ä¸­æ–‡æ•°æ®)ã€‚å…·ä½“ä»£ç å’Œé…ç½®å¦‚ä¸‹ï¼š



- æ¨¡å‹é¢„è®­ç»ƒè„šæœ¬ï¼š[train/pretrain/pretrain.sh](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/pretrain/pretrain.sh)
- é¢„è®­ç»ƒå®ç°ä»£ç ï¼š[train/pretrain/pretrain_clm.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/pretrain/pretrain_clm.py)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)åŠ é€Ÿï¼š
  - å¯¹äºå•å¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-2çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ [train/pretrain/ds_config_zero2.json](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/pretrain/ds_config_zero2.json)
  - å¯¹äºå¤šå¡è®­ç»ƒï¼Œå¯ä»¥é‡‡ç”¨ZeRO-3çš„æ–¹å¼ï¼Œå‚æ•°é…ç½®è§ [train/pretrain/ds_config_zero3.json](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/pretrain/ds_config_zero3.json)
- è®­ç»ƒæ•ˆæœåº¦é‡æŒ‡æ ‡ï¼š[train/pretrain/accuracy.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/pretrain/accuracy.py)

## ğŸ’¡ æ¨¡å‹å¾®è°ƒ

æœ¬ä»“åº“ä¸­åŒæ—¶æä¾›äº†LoRAå¾®è°ƒå’Œå…¨é‡å‚æ•°å¾®è°ƒä»£ç ï¼Œå…³äºLoRAçš„è¯¦ç»†ä»‹ç»å¯ä»¥å‚è€ƒè®ºæ–‡â€œ[LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)â€ä»¥åŠå¾®è½¯Githubä»“åº“[LoRA](https://github.com/microsoft/LoRA)ã€‚

### Step1: ç¯å¢ƒå‡†å¤‡

æ ¹æ®[requirements.txt](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/requirements.txt)å®‰è£…å¯¹åº”çš„ç¯å¢ƒä¾èµ–ã€‚

### Step2: æ•°æ®å‡†å¤‡
åœ¨dataç›®å½•ä¸‹æä¾›äº†ä¸€ä»½ç”¨äºæ¨¡å‹sftçš„æ•°æ®æ ·ä¾‹ï¼š
- è®­ç»ƒæ•°æ®ï¼š[data/train_sft.csv](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/data/train_sft.csv)
- éªŒè¯æ•°æ®ï¼š[data/dev_sft.csv](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/data/dev_sft.csv)

æ¯ä¸ªcsvæ–‡ä»¶ä¸­åŒ…å«ä¸€åˆ—â€œtextâ€ï¼Œæ¯ä¸€è¡Œä¸ºä¸€ä¸ªè®­ç»ƒæ ·ä¾‹ï¼Œæ¯ä¸ªè®­ç»ƒæ ·ä¾‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼å°†é—®é¢˜å’Œç­”æ¡ˆç»„ç»‡ä¸ºæ¨¡å‹è¾“å…¥ï¼Œæ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è‡ªå®šä¹‰è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†ï¼š
```
"<s>Human: "+é—®é¢˜+"\n</s><s>Assistant: "+ç­”æ¡ˆ
```
ä¾‹å¦‚ï¼Œ
```
<s>Human: ç”¨ä¸€å¥è¯æè¿°åœ°çƒä¸ºä»€ä¹ˆæ˜¯ç‹¬ä¸€æ— äºŒçš„ã€‚</s><s>Assistant: å› ä¸ºåœ°çƒæ˜¯ç›®å‰ä¸ºæ­¢å”¯ä¸€å·²çŸ¥å­˜åœ¨ç”Ÿå‘½çš„è¡Œæ˜Ÿã€‚</s>
```

### Step3: å¾®è°ƒè„šæœ¬

#### LoRAå¾®è°ƒ
LoRAå¾®è°ƒè„šæœ¬è§ï¼š[train/sft/finetune_lora.sh](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune_lora.sh)ï¼Œå…³äºLoRAå¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§[train/sft/finetune_clm_lora.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune_clm_lora.py)ï¼Œå•æœºå¤šå¡çš„å¾®è°ƒå¯ä»¥é€šè¿‡ä¿®æ”¹è„šæœ¬ä¸­çš„`--include localhost:0`æ¥å®ç°ã€‚

#### å…¨é‡å‚æ•°å¾®è°ƒ
å…¨é‡å‚æ•°å¾®è°ƒè„šæœ¬è§ï¼š[train/sft/finetune.sh](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune.sh)ï¼Œå…³äºå…¨é‡å‚æ•°å¾®è°ƒçš„å…·ä½“å®ç°ä»£ç è§[train/sft/finetune_clm.py](https://github.com/FlagAlpha/Llama2-Chinese/blob/main/train/sft/finetune_clm.py)ã€‚


### Step4: åŠ è½½å¾®è°ƒæ¨¡å‹

#### LoRAå¾®è°ƒ
åŸºäºLoRAå¾®è°ƒçš„æ¨¡å‹å‚æ•°è§ï¼š[åŸºäºLlama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹](#åŸºäºllama2çš„ä¸­æ–‡å¾®è°ƒæ¨¡å‹)ï¼ŒLoRAå‚æ•°éœ€è¦å’ŒåŸºç¡€æ¨¡å‹å‚æ•°ç»“åˆä½¿ç”¨ã€‚

é€šè¿‡[PEFT](https://github.com/huggingface/peft)åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å‚æ•°å’Œå¾®è°ƒæ¨¡å‹å‚æ•°ï¼Œä»¥ä¸‹ç¤ºä¾‹ä»£ç ä¸­ï¼Œbase_model_name_or_pathä¸ºé¢„è®­ç»ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ï¼Œfinetune_model_pathä¸ºå¾®è°ƒæ¨¡å‹å‚æ•°ä¿å­˜è·¯å¾„ã€‚

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel,PeftConfig
# ä¾‹å¦‚: finetune_model_path='FlagAlpha/Llama2-Chinese-7b-Chat-LoRA'
finetune_model_path=''  
config = PeftConfig.from_pretrained(finetune_model_path)
# ä¾‹å¦‚: base_model_name_or_path='meta-llama/Llama-2-7b-chat'
tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path,use_fast=False)
tokenizer.pad_token = tokenizer.eos_token
model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,device_map='auto',torch_dtype=torch.float16,load_in_8bit=True)
model = PeftModel.from_pretrained(model, finetune_model_path, device_map={"": 0})
model =model.eval()
input_ids = tokenizer(['<s>Human: ä»‹ç»ä¸€ä¸‹åŒ—äº¬\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```



## ğŸ„ æ¨¡å‹é‡åŒ–
æˆ‘ä»¬å¯¹ä¸­æ–‡å¾®è°ƒçš„æ¨¡å‹å‚æ•°è¿›è¡Œäº†é‡åŒ–ï¼Œæ–¹ä¾¿ä»¥æ›´å°‘çš„è®¡ç®—èµ„æºè¿è¡Œã€‚ç›®å‰å·²ç»åœ¨[Hugging Face](https://huggingface.co/FlagAlpha)ä¸Šä¼ äº†13Bä¸­æ–‡å¾®è°ƒæ¨¡å‹[FlagAlpha/Llama2-Chinese-13b-Chat](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat)çš„4bitå‹ç¼©ç‰ˆæœ¬[FlagAlpha/Llama2-Chinese-13b-Chat-4bit](https://huggingface.co/FlagAlpha/Llama2-Chinese-13b-Chat-4bit)ï¼Œå…·ä½“è°ƒç”¨æ–¹å¼å¦‚ä¸‹ï¼š
```python
from transformers import AutoTokenizer
from auto_gptq import AutoGPTQForCausalLM
model = AutoGPTQForCausalLM.from_quantized('FlagAlpha/Llama2-Chinese-13b-Chat-4bit', device="cuda:0")
tokenizer = AutoTokenizer.from_pretrained('FlagAlpha/Llama2-Chinese-13b-Chat-4bit',use_fast=False)
input_ids = tokenizer(['<s>Human: æ€ä¹ˆç™»ä¸Šç«æ˜Ÿ\n</s><s>Assistant: '], return_tensors="pt",add_special_tokens=False).input_ids.to('cuda')        
generate_input = {
    "input_ids":input_ids,
    "max_new_tokens":512,
    "do_sample":True,
    "top_k":50,
    "top_p":0.95,
    "temperature":0.3,
    "repetition_penalty":1.3,
    "eos_token_id":tokenizer.eos_token_id,
    "bos_token_id":tokenizer.bos_token_id,
    "pad_token_id":tokenizer.pad_token_id
}
generate_ids  = model.generate(**generate_input)
text = tokenizer.decode(generate_ids[0])
print(text)
```


## ğŸ¥‡ æ¨¡å‹è¯„æµ‹

æµ‹è¯•ä¸­ä½¿ç”¨çš„Promptå¦‚ä¸‹ï¼Œä¾‹å¦‚å¯¹äºé—®é¢˜â€œåˆ—å‡º5ç§å¯ä»¥æ”¹å–„ç¡çœ è´¨é‡çš„æ–¹æ³•â€ï¼š
```

```

é€šè¿‡æµ‹è¯•æˆ‘ä»¬å‘ç°ï¼ŒMetaåŸå§‹çš„Llama2 Chatæ¨¡å‹å¯¹äºä¸­æ–‡é—®ç­”çš„å¯¹é½æ•ˆæœä¸€èˆ¬ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹éƒ½ä¸èƒ½ç»™å‡ºä¸­æ–‡å›ç­”ï¼Œæˆ–è€…æ˜¯ä¸­è‹±æ–‡æ··æ‚çš„å½¢å¼ã€‚å› æ­¤ï¼ŒåŸºäºä¸­æ–‡æ•°æ®å¯¹Llama2æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œå¾®è°ƒååˆ†å¿…è¦ï¼Œæˆ‘ä»¬çš„ä¸­æ–‡ç‰ˆLlama2æ¨¡å‹ä¹Ÿå·²ç»åœ¨è®­ç»ƒä¸­ï¼Œè¿‘æœŸå°†å¯¹ç¤¾åŒºå¼€æ”¾ã€‚



### å‚è€ƒç›¸å…³è®ºæ–‡
* [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)




<p align="center" width="100%">
<img src="https://starchart.cc/kingTLE/literary-alpaca2.svg" alt="Star History" style="width: 100%; display: block; margin: auto;">
</p>
